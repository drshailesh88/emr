name: Nightly Tests

on:
  schedule:
    # Run at 2 AM UTC every day
    - cron: '0 2 * * *'
  workflow_dispatch:

env:
  PYTHON_VERSION: '3.11'

jobs:
  full-test-suite:
    name: Full Test Suite
    runs-on: ubuntu-latest
    timeout-minutes: 120
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-cov pytest-xdist pytest-timeout pytest-benchmark

      - name: Set up test environment
        run: |
          mkdir -p data
          mkdir -p data/chroma

      - name: Run all tests (including slow tests)
        run: |
          pytest tests/ -v \
            --cov=src \
            --cov-report=xml \
            --cov-report=html \
            --cov-report=term-missing \
            --timeout=1800 \
            -n auto \
            --tb=long \
            --maxfail=10

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: nightly-test-results
          path: |
            htmlcov/
            coverage.xml
          retention-days: 30

  integration-tests:
    name: Integration Tests with Real Database
    runs-on: ubuntu-latest
    timeout-minutes: 60
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-timeout

      - name: Set up integration test database
        run: |
          mkdir -p data
          python -c "from src.services.database import Database; db = Database('data/integration.db'); db.init_db()"

      - name: Populate test data
        run: |
          python -c "
          from src.services.database import Database
          import random
          import datetime

          db = Database('data/integration.db')

          # Create test patients
          for i in range(100):
              db.add_patient(
                  name=f'Test Patient {i}',
                  age=random.randint(20, 80),
                  gender=random.choice(['M', 'F', 'O']),
                  phone=f'98765{i:05d}',
                  address=f'Address {i}'
              )
          print('Created 100 test patients')
          "

      - name: Run integration tests
        run: |
          pytest tests/ -v \
            --timeout=3600 \
            -m "integration" \
            --tb=long

      - name: Upload integration test artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: integration-test-artifacts
          path: data/
          retention-days: 7

  load-tests:
    name: Load and Performance Tests
    runs-on: ubuntu-latest
    timeout-minutes: 60
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-benchmark locust

      - name: Run performance benchmarks
        run: |
          pytest tests/ -v \
            -m "benchmark" \
            --benchmark-only \
            --benchmark-json=benchmark-results.json \
            --benchmark-min-rounds=10

      - name: Run database load tests
        run: |
          python -c "
          from src.services.database import Database
          import time
          import random

          db = Database('data/load_test.db')
          db.init_db()

          # Test 1: Bulk patient creation
          start = time.time()
          for i in range(1000):
              db.add_patient(
                  name=f'Load Test {i}',
                  age=random.randint(20, 80),
                  gender=random.choice(['M', 'F', 'O']),
                  phone=f'99999{i:05d}',
                  address=f'Test Address {i}'
              )
          duration = time.time() - start
          print(f'Created 1000 patients in {duration:.2f}s ({1000/duration:.2f} patients/s)')

          # Test 2: Bulk read performance
          start = time.time()
          for i in range(1000):
              patients = db.search_patients(f'Load Test {i}')
          duration = time.time() - start
          print(f'Performed 1000 searches in {duration:.2f}s ({1000/duration:.2f} searches/s)')
          "

      - name: Upload performance results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: performance-results
          path: benchmark-results.json
          retention-days: 90

  rag-performance-tests:
    name: RAG Performance Tests
    runs-on: ubuntu-latest
    timeout-minutes: 60
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Test ChromaDB performance
        run: |
          python -c "
          from src.services.rag import RAGService
          import time

          rag = RAGService('data/chroma_test')

          # Test 1: Bulk embedding creation
          start = time.time()
          for i in range(100):
              rag.add_document(
                  document_id=f'doc_{i}',
                  text=f'This is test document {i} with some clinical content about patient care and treatment.',
                  metadata={'type': 'test', 'index': i}
              )
          duration = time.time() - start
          print(f'Created 100 embeddings in {duration:.2f}s ({100/duration:.2f} docs/s)')

          # Test 2: Search performance
          start = time.time()
          for i in range(100):
              results = rag.search('patient treatment', n_results=5)
          duration = time.time() - start
          print(f'Performed 100 searches in {duration:.2f}s ({100/duration:.2f} searches/s)')
          "

      - name: Upload RAG performance results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: rag-performance-results
          path: data/chroma_test/
          retention-days: 7

  memory-leak-tests:
    name: Memory Leak Detection
    runs-on: ubuntu-latest
    timeout-minutes: 60
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-memray memory_profiler

      - name: Run memory profiling
        run: |
          python -m memory_profiler tests/test_memory_profile.py || echo "Memory profile completed"

      - name: Check for memory leaks
        continue-on-error: true
        run: |
          pytest tests/ -v \
            -m "memory" \
            --memray \
            --tb=short || echo "Memory tests completed"

  compatibility-tests:
    name: Multi-Python Version Tests
    runs-on: ${{ matrix.os }}
    timeout-minutes: 60
    strategy:
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        python-version: ['3.11', '3.12']
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest

      - name: Run compatibility tests
        run: |
          pytest tests/ -v \
            -m "not slow and not integration" \
            --tb=short

  notify-results:
    name: Notify Test Results
    runs-on: ubuntu-latest
    needs: [full-test-suite, integration-tests, load-tests, rag-performance-tests, memory-leak-tests, compatibility-tests]
    if: always()
    steps:
      - name: Check test status
        run: |
          echo "Nightly Test Summary"
          echo "===================="
          echo "Full Test Suite: ${{ needs.full-test-suite.result }}"
          echo "Integration Tests: ${{ needs.integration-tests.result }}"
          echo "Load Tests: ${{ needs.load-tests.result }}"
          echo "RAG Performance: ${{ needs.rag-performance-tests.result }}"
          echo "Memory Leak Tests: ${{ needs.memory-leak-tests.result }}"
          echo "Compatibility Tests: ${{ needs.compatibility-tests.result }}"

      - name: Send failure notification
        if: |
          needs.full-test-suite.result == 'failure' ||
          needs.integration-tests.result == 'failure' ||
          needs.load-tests.result == 'failure' ||
          needs.rag-performance-tests.result == 'failure' ||
          needs.compatibility-tests.result == 'failure'
        run: |
          echo "ALERT: Nightly tests failed!"
          echo "Please check the GitHub Actions logs for details."
          # Add Slack/email notification here
          # Example Slack webhook:
          # curl -X POST -H 'Content-type: application/json' \
          #   --data '{"text":"Nightly tests failed for DocAssist EMR"}' \
          #   ${{ secrets.SLACK_WEBHOOK_URL }}

      - name: Create issue on failure
        if: |
          needs.full-test-suite.result == 'failure' ||
          needs.integration-tests.result == 'failure' ||
          needs.compatibility-tests.result == 'failure'
        uses: actions/github-script@v7
        with:
          script: |
            const today = new Date().toISOString().split('T')[0];
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `Nightly Test Failure - ${today}`,
              body: `## Nightly Test Results

              The nightly test suite has failed. Please investigate.

              **Test Results:**
              - Full Test Suite: ${{ needs.full-test-suite.result }}
              - Integration Tests: ${{ needs.integration-tests.result }}
              - Load Tests: ${{ needs.load-tests.result }}
              - RAG Performance: ${{ needs.rag-performance-tests.result }}
              - Memory Leak Tests: ${{ needs.memory-leak-tests.result }}
              - Compatibility Tests: ${{ needs.compatibility-tests.result }}

              **Workflow Run:** ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
              `,
              labels: ['bug', 'nightly-test-failure', 'priority:high']
            });
